{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet regression micro-bead tracker\n",
    "## Find the position of one micro-bead in the image \n",
    "Using DL regression based on convnet + densely connected layers.\n",
    "The training, validation and test-data are generated by simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import holodeep2D\n",
    "\n",
    "# physics parameters for the simulations:\n",
    "n_m  = 1.339        # refractive index medium\n",
    "n_p  = 1.59         # index sphere (polystirene: 1.55-1.59):\n",
    "lamb = 0.660        # illumination wavelength (microns)\n",
    "umpp = 0.300        # camera micron (um) per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_test_set(num_imgs=5000):\n",
    "    ''' return and save the training set, by making 'num_imgs' hologram images. '''    \n",
    "    # parameters (modify them):\n",
    "    img_dim_px = [20,20]\n",
    "    savename = '' #'./holodeep_trainset'\n",
    "    img_scale = .7\n",
    "    bead_rad_um = 0.5\n",
    "    bead_zmin_um = -3.3\n",
    "    bead_zmax_um = -3.3\n",
    "    bead_noise = 0.05\n",
    "    # init images:\n",
    "    imgs = np.zeros((num_imgs, img_dim_px[0], img_dim_px[1]))\n",
    "    # init data labels:\n",
    "    pos  = np.zeros((num_imgs, 3))                                                                                          \n",
    "    # make rand holograms images:\n",
    "    for img_i in range(num_imgs):\n",
    "        print('creating image: '+str(img_i)+' /'+str(num_imgs), end='\\r')\n",
    "        # make bead hologram:\n",
    "        d_i = holodeep2D.make_bead_holo(img_dim_px=img_dim_px, img_scale=img_scale, bead_rad_um=bead_rad_um, zmin_um=bead_zmin_um, zmax_um=bead_zmax_um, noise=bead_noise, plots=False)\n",
    "        imgs[img_i,:,:] = d_i['holo_bead']\n",
    "        pos[img_i,:]    = d_i['holo_bead_pos_px']\n",
    "    # normalize the image data to mean 0 and std 1. \n",
    "    X = (imgs - np.mean(imgs)) / np.std(imgs)\n",
    "    # normalize labels (x,y,z) so x,y are in 0,1:\n",
    "    Y = pos/np.array((img_dim_px[0], img_dim_px[1], 1)) + np.array((0.5, 0.5, 0))\n",
    "    Y = Y[:,:2]\n",
    "    if savename:\n",
    "        np.save(savename, {'X':X, 'Y':Y})\n",
    "        print('saved: '+savename+'.npy')\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create by simulation training images (X) and labels (Y).\n",
    "Y gives the 2D position of the bead in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = make_training_test_set(num_imgs=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one image with its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0])\n",
    "plt.title(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define here the network. Change the hyper parameters to make it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    ''' define and compile the model. \n",
    "    input_shape : include the channel as in [img_dim_px[0], img_dim_px[1], 1]\n",
    "    label_shape : 3 or 2\n",
    "    '''\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout, BatchNormalization\n",
    "    from keras import optimizers \n",
    "    from keras import regularizers\n",
    "    label_shape = 2\n",
    "    input_shape = (20,20,1)\n",
    "    model = Sequential()\n",
    "    # define model architecture:\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', padding='valid', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='valid', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(label_shape, activation=None))\n",
    "    # compile model:\n",
    "    model.compile(loss='mean_squared_error', optimizer='adamax', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_model(model):\n",
    "    ''' plot training history '''\n",
    "    loss = model.history.history['loss']\n",
    "    acc  = model.history.history['acc']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    val_acc  = model.history.history['val_acc']\n",
    "    epochs = model.history.epoch\n",
    "    fig = plt.figure('train_model()', clear=False)\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    ax1.semilogy(epochs, loss, label='loss')\n",
    "    ax1.semilogy(epochs, val_loss, label='val_loss')\n",
    "    ax1.legend()\n",
    "    ax2.plot(epochs, acc, label='acc') \n",
    "    ax2.plot(epochs, val_acc, label='val_acc') \n",
    "    ax2.set_xlabel('epochs')\n",
    "    ax2.legend()\n",
    "\n",
    "    \n",
    "model = define_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model here, and plot its history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, epochs=10):\n",
    "    ''' returns trained model '''\n",
    "    history = model.fit(x=X[:,:,:,np.newaxis], y=Y, epochs=epochs, batch_size=16, verbose=1, validation_split=0.2)\n",
    "    plot_model(model)\n",
    "    return model\n",
    "\n",
    "model = train_model(model, X,Y, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on a test set which resembles the experiment\n",
    "(the bead moves along a circular trajectory of diameter 'ampl' pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, nimgs=100, ampl=3):\n",
    "    ''' a test set for the trained model'''\n",
    "    X = np.zeros((nimgs, 20, 20, 1))\n",
    "    Y = np.zeros((nimgs, 2))\n",
    "    w = 0.1\n",
    "    for i in range(nimgs):\n",
    "        print(f'creating test set {i} / {nimgs}', end='\\r')\n",
    "        x = ampl*np.sin(w*i)   \n",
    "        y = ampl*np.cos(w*i)  \n",
    "        z = -3.3/umpp #(- 6.5 - i/nimgs)/umpp\n",
    "        d = holodeep2D.make_bead_holo(xyzpos_px=[x,y,z])\n",
    "        X[i,:,:,0] = d['holo_bead']\n",
    "        Y[i,:] = d['holo_bead_pos_px'][:2]\n",
    "    # normalize:\n",
    "    X = (X - np.mean(X))/np.std(X)\n",
    "    Y = Y/20 + 0.5\n",
    "    # predict:\n",
    "    pred = model.predict(X)\n",
    "    # error (distance predictions - truth):\n",
    "    err_rel = np.hypot(Y[:,0] - pred[:,0], Y[:,1] - pred[:,1])\n",
    "    err_px = err_rel*20\n",
    "    # plots:\n",
    "    plt.figure('test_model()', clear=False)\n",
    "    plt.subplot(211)\n",
    "    plt.plot((Y[:,0]-0.5)*20, (Y[:,1]-0.5)*20, '.', label='truth')\n",
    "    plt.plot((pred[:,0]-0.5)*20, (pred[:,1]-0.5)*20, 'o', alpha=0.2, label='prediction')\n",
    "    plt.axis('scaled')\n",
    "    plt.xlabel('px')\n",
    "    plt.ylabel('px')\n",
    "    plt.subplot(212)\n",
    "    plt.hist(err_px, 20, alpha=0.3)\n",
    "    plt.xlabel('error (px)')\n",
    "    plt.ylabel('n.points')\n",
    "    plt.title(f'mean error : {np.mean(err_px):.3f} px ({np.mean(err_px)*umpp:.3f} um)', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "test_model(model, nimgs=300, ampl=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
