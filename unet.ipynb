{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET for image segmentation of bacteria\n",
    "#### we use UNET to classify each pixel of the image of bacteria on a surface. Each pixel can belong to the following classes:\n",
    "- cell interior\n",
    "- cell membrane\n",
    "- background\n",
    "- other stuff (mainly spherical)\n",
    "\n",
    "Here we define the class `Unet` which contains everything we need.  \n",
    "The parameters used to build the UNET network are described in the function `__init__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "import PIL\n",
    "import os\n",
    "\n",
    "\n",
    "class Unet():\n",
    "\n",
    "\n",
    "    def __init__(self, num_images=100, img_w=48, img_h=48, start_ch=64, depth=4, inc_rate=2., activation='relu', dropout=0, batchnorm=True, maxpool=True, upconv=True, residual=False, batch_size=16, epochs=5, trainit=False):\n",
    "        '''\n",
    "            Credit: https://github.com/pietz/unet-keras/blob/master/unet.py\n",
    "\n",
    "            U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "            (https://arxiv.org/abs/1505.04597)\n",
    "            ---\n",
    "            img_shape:  (height, width, channels)\n",
    "            start_ch:   number of channels of the first conv layer\n",
    "            depth:      zero indexed depth of the U-structure\n",
    "            inc_rate:   rate at which the conv channels will increase\n",
    "            activation: activation function after convolutions\n",
    "            dropout:    amount of dropout in the contracting part\n",
    "            batchnorm:  adds Batch Normalization if true\n",
    "            maxpool:    use strided conv instead of maxpooling if false\n",
    "            upconv:     use transposed conv instead of upsamping + conv if false\n",
    "            residual:   add residual connections around each conv block if true\n",
    "        '''\n",
    "\n",
    "        self.basepath = 'Training_ImDatabase_FCN_Myxo/' \n",
    "        self.num_images = num_images\n",
    "        self.img_w = img_w        \n",
    "        self.img_h = img_h        \n",
    "        \n",
    "        #self.out_ch = out_ch\n",
    "        self.start_ch = start_ch\n",
    "        self.depth = depth\n",
    "        self.inc_rate = inc_rate\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.batchnorm = batchnorm\n",
    "        self.maxpool = maxpool\n",
    "        self.upconv = upconv\n",
    "        self.residual = residual\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.make_sets(self.num_images)\n",
    "        self.def_unet()\n",
    "        if trainit:\n",
    "            self.train_unet()\n",
    "            self.plot_history()\n",
    "            self.show_val()\n",
    "\n",
    "\n",
    "    def open_one_image(self, imagefile=None, plots=False):\n",
    "        ''' open, crop image'''\n",
    "        if not imagefile:\n",
    "            imagefile = self.imagefile\n",
    "        img = PIL.Image.open(imagefile)\n",
    "        # open and crop:\n",
    "        img = np.array(img.getdata()).reshape(img.size)\n",
    "        img = img[:self.img_h, :self.img_w]\n",
    "        if plots:\n",
    "            plt.figure('open_one_image', clear=True)\n",
    "            plt.imshow(img)\n",
    "            plt.colorbar()\n",
    "        return img\n",
    "\n",
    "\n",
    "    \n",
    "    def make_sets(self, num_images=100):\n",
    "        ''' read, crop, and store training testing npy images \n",
    "            num_images : take all if None\n",
    "            TODO include only files with 1,120,220 without converting labels\n",
    "        '''\n",
    "        l_train_orig = np.sort(os.listdir(self.basepath+'Training/Original/'))\n",
    "        if num_images == None:\n",
    "            num_images = len(l_train_orig)\n",
    "        # init sets:\n",
    "        self.train_set = np.zeros((num_images, self.img_h, self.img_w))\n",
    "        self.train_lab = np.zeros((num_images, self.img_h, self.img_w))\n",
    "        #Â open store images:\n",
    "        for i in range(num_images):\n",
    "            f = l_train_orig[i]\n",
    "            print(f'make_sets(): Loading {f} {i}/{num_images-1}', end='\\r')\n",
    "            lab = self.open_one_image(self.basepath + 'Training/Labeled/' + f)\n",
    "            # convert 100 200 labels (e.coli):\n",
    "            lab[np.nonzero(lab == 100)] = 120            \n",
    "            lab[np.nonzero(lab == 200)] = 220            \n",
    "            self.train_set[i] = self.open_one_image(self.basepath + 'Training/Original/' + f)\n",
    "            self.train_lab[i] = lab\n",
    "        # normalize training set:\n",
    "        self.train_set = (self.train_set - np.mean(self.train_set, axis=0))/np.std(self.train_set, axis=0)\n",
    "        self.train_set = self.train_set[:,:,:,np.newaxis]\n",
    "        # normalize training labels:\n",
    "        self.num_labels = len(np.unique(self.train_lab))\n",
    "        for i, l in enumerate(np.unique(self.train_lab)):\n",
    "            self.train_lab[np.nonzero(self.train_lab == l)] = i\n",
    "        # labels to categorical:\n",
    "        self.train_lab = to_categorical(self.train_lab, self.num_labels)\n",
    "        print(f'\\nmake_sets(): found {self.num_labels} labels')\n",
    "         \n",
    "\n",
    "    def def_unet(self):\n",
    "\n",
    "        def conv_block(m, dim, acti, bn, res, do=0):\n",
    "            n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
    "            n = BatchNormalization()(n) if bn else n\n",
    "            n = Dropout(do)(n) if do else n\n",
    "            n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
    "            n = BatchNormalization()(n) if bn else n\n",
    "            return Concatenate()([m, n]) if res else n\n",
    "        \n",
    "        def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
    "            if depth > 0:\n",
    "                n = conv_block(m, dim, acti, bn, res)\n",
    "                m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
    "                m = level_block(m, int(inc*dim), depth-1, inc, acti, do, bn, mp, up, res)\n",
    "                if up:\n",
    "                    m = UpSampling2D()(m)\n",
    "                    m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
    "                else:\n",
    "                    m = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n",
    "                n = Concatenate()([n, m])\n",
    "                m = conv_block(n, dim, acti, bn, res)\n",
    "            else:\n",
    "                m = conv_block(m, dim, acti, bn, res, do)\n",
    "            return m\n",
    "\n",
    "        print('def_unet(): model init...')\n",
    "        img_shape = (self.img_w, self.img_h, 1)\n",
    "        out_ch = self.num_labels\n",
    "        start_ch = self.start_ch\n",
    "        depth = self.depth\n",
    "        inc_rate = self.inc_rate\n",
    "        activation = self.activation\n",
    "        dropout = self.dropout\n",
    "        batchnorm = self.batchnorm\n",
    "        maxpool = self.maxpool\n",
    "        upconv = self.upconv\n",
    "        residual = self.residual\n",
    "\n",
    "        i = Input(shape=img_shape)\n",
    "        o = level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)\n",
    "        o = Conv2D(out_ch, 1, activation='softmax')(o)\n",
    "        # model:\n",
    "        self.model = Model(inputs=i, outputs=o)\n",
    "        # compile:\n",
    "        print('def_unet(): model compile...')\n",
    "        self.model.compile(optimizer='Adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        print('def_unet(): done.')\n",
    "    \n",
    "    \n",
    "    def train_unet(self):\n",
    "        self.model.fit( x=self.train_set, \n",
    "                        y=self.train_lab, \n",
    "                        batch_size=self.batch_size, \n",
    "                        epochs=self.epochs, \n",
    "                        verbose=1, \n",
    "                        validation_split=0.2 )\n",
    "\n",
    "\n",
    "    def plot_history(self):\n",
    "        loss = self.model.history.history['loss']\n",
    "        val_loss = self.model.history.history['val_loss']\n",
    "        epochs = self.model.history.epoch\n",
    "        plt.figure('plot_history', clear=False)\n",
    "        plt.semilogy(epochs, loss, label='loss')\n",
    "        plt.semilogy(epochs, val_loss, label='val_loss')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.legend()\n",
    "\n",
    "   \n",
    "\n",
    "    def show_val(self, imgidx=0):\n",
    "        img  = self.model.history.validation_data[0][imgidx,...,0]\n",
    "        lab1 = self.model.history.validation_data[1][imgidx,...,0]\n",
    "        lab2 = self.model.history.validation_data[1][imgidx,...,1]\n",
    "        lab3 = self.model.history.validation_data[1][imgidx,...,2]\n",
    "        if self.num_labels == 4:\n",
    "            lab4 = self.model.history.validation_data[1][imgidx,...,3]\n",
    "        else:\n",
    "            lab4 = lab3\n",
    "        loss = self.model.history.history['loss']\n",
    "        val_loss = self.model.history.history['val_loss']\n",
    "        epochs = self.model.history.epoch\n",
    "        fig = plt.figure('show_val', clear=True, figsize=(7.5,7.5))\n",
    "        ax1 = fig.add_subplot(321)\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title(f'val[{imgidx}]')\n",
    "        ax2 = fig.add_subplot(322)\n",
    "        ax2.imshow(img + 4*lab4)\n",
    "        ax2.set_title('img+lab4')\n",
    "        ax3 = fig.add_subplot(345)\n",
    "        ax3.imshow(lab1)\n",
    "        ax3.set_title('lab1')\n",
    "        ax4 = fig.add_subplot(346)\n",
    "        ax4.imshow(lab2)\n",
    "        ax4.set_title('lab2')\n",
    "        ax5 = fig.add_subplot(347)\n",
    "        ax5.imshow(lab3)\n",
    "        ax5.set_title('lab3')\n",
    "        ax6 = fig.add_subplot(348)\n",
    "        ax6.imshow(lab4)\n",
    "        ax6.set_title('lab4')\n",
    "        ax7 = fig.add_subplot(313)\n",
    "        ax7.semilogy(epochs, loss, label='loss')\n",
    "        ax7.semilogy(epochs, val_loss, label='val_loss')\n",
    "        ax7.set_xlabel('epochs')\n",
    "        ax7.legend()\n",
    "\n",
    "\n",
    "    def check_predition(self, imgidx=0):\n",
    "        pred = self.model.predict()\n",
    "                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_sets(): Loading 00199_Myxo.tif 199/199\n",
      "make_sets(): found 3 labels\n",
      "def_unet(): model init...\n",
      "def_unet(): model compile...\n",
      "def_unet(): done.\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 30s 186ms/step - loss: 0.6853 - acc: 0.7130 - val_loss: 4.9117 - val_acc: 0.5850\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 26s 161ms/step - loss: 0.4316 - acc: 0.8142 - val_loss: 2.5277 - val_acc: 0.6859\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 26s 164ms/step - loss: 0.4298 - acc: 0.8162 - val_loss: 0.8199 - val_acc: 0.7977\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 26s 162ms/step - loss: 0.4236 - acc: 0.8182 - val_loss: 0.3909 - val_acc: 0.8520\n",
      "Epoch 5/5\n",
      "144/160 [==========================>...] - ETA: 2s - loss: 0.4007 - acc: 0.8263"
     ]
    }
   ],
   "source": [
    "unet = Unet(num_images=200, img_w=48, img_h=48, start_ch=64, depth=4, inc_rate=2., activation='relu', dropout=0, batchnorm=True, maxpool=True, upconv=True, residual=False, batch_size=16, epochs=5, trainit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show history and one example image segmented:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unet.show_val(imgidx=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
